/**
 * PromptXY v2.0 æ€§èƒ½åŸºå‡†æµ‹è¯•æ¡†æ¶
 *
 * è®¾è®¡ç›®æ ‡ï¼š
 * 1. å»ºç«‹å…¨é¢çš„æ€§èƒ½æŒ‡æ ‡ä½“ç³»
 * 2. æä¾›å¯é‡å¤çš„æµ‹è¯•åœºæ™¯
 * 3. å®šä¹‰æ˜ç¡®çš„æˆåŠŸæ ‡å‡†
 * 4. ç”Ÿæˆè¯¦ç»†çš„æµ‹è¯•æŠ¥å‘Š
 */

// ==================== æ€§èƒ½æŒ‡æ ‡å®šä¹‰ ====================

export interface PerformanceMetrics {
  // æ—¶é—´æŒ‡æ ‡
  latency: {
    min: number;      // æœ€å°å»¶è¿Ÿ (ms)
    max: number;      // æœ€å¤§å»¶è¿Ÿ (ms)
    avg: number;      // å¹³å‡å»¶è¿Ÿ (ms)
    p50: number;      // 50th ç™¾åˆ†ä½å»¶è¿Ÿ (ms)
    p95: number;      // 95th ç™¾åˆ†ä½å»¶è¿Ÿ (ms)
    p99: number;      // 99th ç™¾åˆ†ä½å»¶è¿Ÿ (ms)
  };

  // ååé‡æŒ‡æ ‡
  throughput: {
    rps: number;      // æ¯ç§’è¯·æ±‚æ•°
    totalRequests: number;  // æ€»è¯·æ±‚æ•°
    successfulRequests: number;  // æˆåŠŸè¯·æ±‚æ•°
    failedRequests: number;  // å¤±è´¥è¯·æ±‚æ•°
    successRate: number;  // æˆåŠŸç‡ (%)
  };

  // èµ„æºä½¿ç”¨
  resources: {
    memory: {
      initial: number;  // åˆå§‹å†…å­˜ (MB)
      peak: number;     // å³°å€¼å†…å­˜ (MB)
      final: number;    // æœ€ç»ˆå†…å­˜ (MB)
      delta: number;    // å†…å­˜å˜åŒ– (MB)
    };
    cpu: {
      avg: number;      // å¹³å‡ CPU ä½¿ç”¨ç‡ (%)
      peak: number;     // å³°å€¼ CPU ä½¿ç”¨ç‡ (%)
    };
  };

  // ç‰¹å®šåœºæ™¯æŒ‡æ ‡
  specific: Record<string, any>;
}

// ==================== æˆåŠŸæ ‡å‡†å®šä¹‰ ====================

export interface SuccessCriteria {
  // å»¶è¿Ÿæ ‡å‡†
  latency: {
    maxAvgLatency: number;      // æœ€å¤§å¹³å‡å»¶è¿Ÿ (ms)
    maxP95Latency: number;      // æœ€å¤§ P95 å»¶è¿Ÿ (ms)
    maxP99Latency: number;      // æœ€å¤§ P99 å»¶è¿Ÿ (ms)
  };

  // ååé‡æ ‡å‡†
  throughput: {
    minRPS: number;             // æœ€å° RPS
    minSuccessRate: number;     // æœ€å°æˆåŠŸç‡ (%)
  };

  // èµ„æºæ ‡å‡†
  resources: {
    maxMemoryIncrease: number;  // æœ€å¤§å†…å­˜å¢é•¿ (MB)
    maxMemoryLeakRate: number;  // æœ€å¤§å†…å­˜æ³„æ¼ç‡ (MB/åˆ†é’Ÿ)
  };

  // ç¨³å®šæ€§æ ‡å‡†
  stability: {
    maxErrorRate: number;       // æœ€å¤§é”™è¯¯ç‡ (%)
    maxConnectionFailures: number;  // æœ€å¤§è¿æ¥å¤±è´¥æ•°
  };
}

// ==================== æµ‹è¯•åœºæ™¯å®šä¹‰ ====================

export interface TestScenario {
  name: string;
  description: string;
  config: TestConfig;
  criteria: SuccessCriteria;
}

export interface TestConfig {
  // å¹¶å‘é…ç½®
  concurrency?: {
    connections: number | number[];
    requestsPerConnection?: number;
    timeout?: number;
  };

  // æ•°æ®è§„æ¨¡
  dataScale?: {
    rules?: number;        // è§„åˆ™æ•°é‡
    records?: number;      // æ•°æ®åº“è®°å½•æ•°
    items?: number;        // åˆ—è¡¨é¡¹æ•°
  };

  // æŒç»­æ—¶é—´
  duration?: {
    warmup: number;        // é¢„çƒ­æ—¶é—´ (ms)
    test: number;          // æµ‹è¯•æ—¶é—´ (ms)
    cooldown: number;      // å†·å´æ—¶é—´ (ms)
  };

  // ç‰¹å®šé…ç½®
  specific?: Record<string, any>;
}

// ==================== åŸºå‡†æµ‹è¯•ç»“æœ ====================

export interface BenchmarkResult {
  scenario: string;
  timestamp: number;
  status: 'pass' | 'fail' | 'warning';
  metrics: PerformanceMetrics;
  criteria: SuccessCriteria;
  violations: string[];
  analysis: string[];
  recommendations: string[];
}

// ==================== åŸºå‡†æµ‹è¯•æŠ¥å‘Š ====================

export interface BenchmarkReport {
  metadata: {
    project: string;
    version: string;
    environment: string;
    timestamp: number;
    duration: number;
  };

  summary: {
    totalTests: number;
    passed: number;
    failed: number;
    overallScore: number;  // 0-100
  };

  results: BenchmarkResult[];

  // æ€§èƒ½è¯„åˆ†
  scoring: {
    backend: {
      overall: number;
      breakdown: {
        throughput: number;
        latency: number;
        resources: number;
        stability: number;
      };
    };
    frontend: {
      overall: number;
      breakdown: {
        rendering: number;
        stateManagement: number;
        memory: number;
        virtualScroll: number;
      };
    };
    e2e: {
      overall: number;
      breakdown: {
        latency: number;
        endToEnd: number;
      };
    };
  };

  // ç“¶é¢ˆåˆ†æ
  bottlenecks: {
    critical: string[];
    warning: string[];
    info: string[];
  };

  // ä¼˜åŒ–å»ºè®®
  recommendations: {
    immediate: string[];
    shortTerm: string[];
    longTerm: string[];
  };
}

// ==================== æµ‹è¯•æ‰§è¡Œå™¨æ¥å£ ====================

export interface BenchmarkExecutor {
  // æ‰§è¡Œæµ‹è¯•
  execute(scenario: TestScenario): Promise<BenchmarkResult>;

  // æ‰¹é‡æ‰§è¡Œ
  executeAll(scenarios: TestScenario[]): Promise<BenchmarkResult[]>;

  // ç”ŸæˆæŠ¥å‘Š
  generateReport(results: BenchmarkResult[]): Promise<BenchmarkReport>;

  // éªŒè¯ç»“æœ
  validate(result: BenchmarkResult): { pass: boolean; violations: string[] };
}

// ==================== æ€§èƒ½åŸºçº¿å®šä¹‰ ====================

export const PerformanceBaselines = {
  // åç«¯åŸºçº¿
  backend: {
    // ååé‡
    throughput: {
      lowConcurrency: { rps: 50, successRate: 95 },      // 10-50 å¹¶å‘
      mediumConcurrency: { rps: 30, successRate: 98 },   // 50-100 å¹¶å‘
      highConcurrency: { rps: 20, successRate: 99 },     // 100+ å¹¶å‘
    },

    // è§„åˆ™å¼•æ“
    rules: {
      singleRule: { avgLatency: 1.0, maxLatency: 5.0 },   // å•æ¡è§„åˆ™
      multipleRules: { avgLatency: 2.0, maxLatency: 10.0 }, // å¤šæ¡è§„åˆ™
      throughput: 100000,  // req/s
    },

    // æ•°æ®åº“
    database: {
      singleWrite: { avgLatency: 10.0, maxLatency: 50.0 },  // å•æ¡å†™å…¥
      batchWrite: { avgLatency: 5.0, maxLatency: 20.0 },    // æ‰¹é‡å†™å…¥
      query: { avgLatency: 5.0, maxLatency: 20.0 },         // æŸ¥è¯¢
    },

    // SSE
    sse: {
      connectionTime: { avg: 50.0, max: 100.0 },  // è¿æ¥å»ºç«‹æ—¶é—´
      maxConnections: 100,                        // æœ€å¤§å¹¶å‘è¿æ¥
      eventLatency: { avg: 10.0, max: 50.0 },    // äº‹ä»¶æ¨é€å»¶è¿Ÿ
    },

    // èµ„æº
    resources: {
      memory: { maxIncrease: 50.0, leakRate: 0.1 },  // å†…å­˜ä½¿ç”¨
      cpu: { maxUsage: 80 },                         // CPU ä½¿ç”¨ç‡
    },
  },

  // å‰ç«¯åŸºçº¿
  frontend: {
    // æ¸²æŸ“æ€§èƒ½
    rendering: {
      componentMount: { avg: 5.0, max: 10.0 },      // ç»„ä»¶æŒ‚è½½
      listRender: { avg: 50.0, max: 100.0 },        // åˆ—è¡¨æ¸²æŸ“ (100é¡¹)
      update: { avg: 20.0, max: 50.0 },             // ç»„ä»¶æ›´æ–°
    },

    // è™šæ‹Ÿæ»šåŠ¨
    virtualScroll: {
      initialRender: { avg: 100.0, max: 200.0 },    // åˆå§‹æ¸²æŸ“ (10ké¡¹)
      scrollPerformance: { avg: 30.0, max: 100.0 }, // æ»šåŠ¨æ€§èƒ½
    },

    // çŠ¶æ€ç®¡ç†
    stateManagement: {
      simpleUpdate: { avg: 1.0, max: 5.0 },         // ç®€å•çŠ¶æ€æ›´æ–°
      batchUpdate: { avg: 10.0, max: 50.0 },        // æ‰¹é‡æ›´æ–°
      subscription: { avg: 0.5, max: 2.0 },         // è®¢é˜…é€šçŸ¥
    },

    // å†…å­˜
    memory: {
      leakTolerance: 0.5,                           // å†…å­˜æ³„æ¼å®¹å¿åº¦ (MB)
      componentLifecycle: { avg: 5.0, max: 10.0 },  // ç»„ä»¶ç”Ÿå‘½å‘¨æœŸ
    },
  },

  // ç«¯åˆ°ç«¯åŸºçº¿
  e2e: {
    completeFlow: { avg: 100.0, max: 200.0 },       // å®Œæ•´è¯·æ±‚æµç¨‹
    ruleApplication: { avg: 50.0, max: 100.0 },     // è§„åˆ™åº”ç”¨åˆ°å“åº”
    uiUpdate: { avg: 30.0, max: 60.0 },             // UI æ›´æ–°åˆ°æ˜¾ç¤º
  },
};

// ==================== æµ‹è¯•å·¥å…·ç±» ====================

export class PerformanceTimer {
  private startTimes: Map<string, number> = new Map();
  private measurements: Map<string, number[]> = new Map();

  start(label: string): void {
    this.startTimes.set(label, performance.now());
  }

  end(label: string): number {
    const start = this.startTimes.get(label);
    if (!start) {
      throw new Error(`Timer "${label}" not started`);
    }
    const duration = performance.now() - start;
    this.startTimes.delete(label);

    // è®°å½•æµ‹é‡å€¼
    if (!this.measurements.has(label)) {
      this.measurements.set(label, []);
    }
    this.measurements.get(label)!.push(duration);

    return duration;
  }

  getMeasurements(label: string): number[] {
    return this.measurements.get(label) || [];
  }

  getStats(label: string): { avg: number; min: number; max: number; p95: number; p99: number } | null {
    const measurements = this.getMeasurements(label);
    if (measurements.length === 0) return null;

    const sorted = [...measurements].sort((a, b) => a - b);
    const avg = sorted.reduce((a, b) => a + b, 0) / sorted.length;
    const min = sorted[0];
    const max = sorted[sorted.length - 1];
    const p95 = sorted[Math.floor(sorted.length * 0.95)];
    const p99 = sorted[Math.floor(sorted.length * 0.99)];

    return { avg, min, max, p95, p99 };
  }

  reset(label?: string): void {
    if (label) {
      this.startTimes.delete(label);
      this.measurements.delete(label);
    } else {
      this.startTimes.clear();
      this.measurements.clear();
    }
  }
}

// ==================== èµ„æºç›‘æ§ç±» ====================

export class ResourceMonitor {
  private snapshots: Array<{ timestamp: number; memory: number; cpu: number }> = [];
  private baselineMemory: number | null = null;

  async snapshot(): Promise<{ memory: number; cpu: number }> {
    // è·å–å†…å­˜ä½¿ç”¨ (Node.js ç¯å¢ƒ)
    const memory = process.memoryUsage();
    const memoryMB = memory.heapUsed / 1024 / 1024;

    // è·å– CPU ä½¿ç”¨ç‡ (éœ€è¦å¤–éƒ¨å·¥å…·ï¼Œè¿™é‡Œè¿”å›ä¼°ç®—å€¼)
    const cpu = await this.getCpuUsage();

    this.snapshots.push({
      timestamp: Date.now(),
      memory: memoryMB,
      cpu,
    });

    return { memory: memoryMB, cpu };
  }

  private async getCpuUsage(): Promise<number> {
    // ç®€åŒ–çš„ CPU ä½¿ç”¨ç‡è·å–
    // å®é™…å®ç°éœ€è¦ä½¿ç”¨ os.cpus() æˆ–å¤–éƒ¨ç›‘æ§å·¥å…·
    return new Promise(resolve => {
      // æ¨¡æ‹Ÿ CPU ä½¿ç”¨ç‡
      resolve(Math.random() * 20 + 10);
    });
  }

  setBaseline(): void {
    if (this.snapshots.length > 0) {
      this.baselineMemory = this.snapshots[this.snapshots.length - 1].memory;
    }
  }

  getMemoryDelta(): number {
    if (!this.baselineMemory || this.snapshots.length === 0) return 0;
    const current = this.snapshots[this.snapshots.length - 1].memory;
    return current - this.baselineMemory;
  }

  getMemoryLeakRate(): number {
    if (this.snapshots.length < 2) return 0;

    const first = this.snapshots[0];
    const last = this.snapshots[this.snapshots.length - 1];
    const duration = (last.timestamp - first.timestamp) / 1000 / 60; // minutes
    const memoryChange = last.memory - first.memory;

    return duration > 0 ? memoryChange / duration : 0;
  }

  getStats(): { avgMemory: number; peakMemory: number; avgCpu: number; peakCpu: number } {
    if (this.snapshots.length === 0) {
      return { avgMemory: 0, peakMemory: 0, avgCpu: 0, peakCpu: 0 };
    }

    const memories = this.snapshots.map(s => s.memory);
    const cpus = this.snapshots.map(s => s.cpu);

    const avgMemory = memories.reduce((a, b) => a + b, 0) / memories.length;
    const peakMemory = Math.max(...memories);
    const avgCpu = cpus.reduce((a, b) => a + b, 0) / cpus.length;
    const peakCpu = Math.max(...cpus);

    return { avgMemory, peakMemory, avgCpu, peakCpu };
  }

  reset(): void {
    this.snapshots = [];
    this.baselineMemory = null;
  }
}

// ==================== æ•°æ®ç”Ÿæˆå™¨ ====================

export class DataGenerator {
  // ç”Ÿæˆæµ‹è¯•è§„åˆ™
  static generateRules(count: number): any[] {
    const rules = [];
    for (let i = 0; i < count; i++) {
      rules.push({
        id: `rule-${i}`,
        enabled: true,
        when: {
          client: ['claude', 'codex', 'gemini'][i % 3],
          field: ['system', 'instructions'][i % 2],
          method: 'POST',
          pathRegex: i % 2 === 0 ? '/v1/chat' : '/v1/completions',
          modelRegex: i % 3 === 0 ? 'claude-3' : i % 3 === 1 ? 'gpt-4' : 'gemini',
        },
        ops: [
          {
            type: ['append', 'prepend', 'replace'][i % 3],
            text: `Test rule ${i}`,
            regex: i % 2 === 0 ? 'test' : undefined,
            replacement: i % 2 === 1 ? 'replaced' : undefined,
          },
        ],
        stop: i % 10 === 0,
      });
    }
    return rules;
  }

  // ç”Ÿæˆæµ‹è¯•è¯·æ±‚ä½“
  static generateRequestBody(size: 'small' | 'medium' | 'large' = 'medium'): any {
    const sizes = {
      small: { system: 'test', instructions: 'test' },
      medium: {
        system: 'You are a helpful assistant with extensive knowledge.',
        instructions: 'Please provide detailed responses with examples.',
      },
      large: {
        system: 'You are an expert AI assistant with deep knowledge across multiple domains including technology, science, mathematics, and creative writing.',
        instructions: 'When responding, please provide comprehensive explanations with multiple examples, consider edge cases, and structure your answers clearly with headings and bullet points for better readability.',
      },
    };
    return sizes[size];
  }

  // ç”Ÿæˆæµ‹è¯•æ•°æ®é›†
  static generateDataset(count: number, type: 'requests' | 'rules' | 'items'): any[] {
    const datasets = {
      requests: Array.from({ length: count }, (_, i) => ({
        id: `req-${i}`,
        timestamp: Date.now() - i * 1000,
        client: ['claude', 'codex', 'gemini'][i % 3],
        path: i % 2 === 0 ? '/v1/chat' : '/v1/completions',
        method: 'POST',
      })),
      rules: this.generateRules(count),
      items: Array.from({ length: count }, (_, i) => ({
        id: i,
        content: `Item ${i}: ${'x'.repeat(Math.random() * 200 + 50)}`,
        timestamp: Date.now() - i * 1000,
      })),
    };
    return datasets[type];
  }
}

// ==================== æŠ¥å‘Šç”Ÿæˆå™¨ ====================

export class ReportGenerator {
  static generateMarkdown(report: BenchmarkReport): string {
    let md = `# PromptXY v2.0 æ€§èƒ½åŸºå‡†æµ‹è¯•æŠ¥å‘Š\n\n`;

    // å…ƒæ•°æ®
    md += `## ğŸ“Š æµ‹è¯•æ¦‚è§ˆ\n\n`;
    md += `- **é¡¹ç›®**: ${report.metadata.project}\n`;
    md += `- **ç‰ˆæœ¬**: ${report.metadata.version}\n`;
    md += `- **ç¯å¢ƒ**: ${report.metadata.environment}\n`;
    md += `- **æ—¶é—´**: ${new Date(report.metadata.timestamp).toLocaleString()}\n`;
    md += `- **æ€»è€—æ—¶**: ${(report.metadata.duration / 1000).toFixed(2)}s\n\n`;

    // æ€»ç»“
    md += `## ğŸ¯ æµ‹è¯•æ€»ç»“\n\n`;
    md += `- **æ€»æµ‹è¯•æ•°**: ${report.summary.totalTests}\n`;
    md += `- **é€šè¿‡**: ${report.summary.passed} âœ…\n`;
    md += `- **å¤±è´¥**: ${report.summary.failed} âŒ\n`;
    md += `- **ç»¼åˆè¯„åˆ†**: ${report.summary.overallScore.toFixed(1)}/100\n\n`;

    // è¯„åˆ†è¯¦æƒ…
    md += `## ğŸ“ˆ æ€§èƒ½è¯„åˆ†\n\n`;

    md += `### åç«¯è¯„åˆ† (${report.scoring.backend.overall.toFixed(1)}/100)\n`;
    md += `- ååé‡: ${report.scoring.backend.breakdown.throughput.toFixed(1)}/100\n`;
    md += `- å»¶è¿Ÿ: ${report.scoring.backend.breakdown.latency.toFixed(1)}/100\n`;
    md += `- èµ„æº: ${report.scoring.backend.breakdown.resources.toFixed(1)}/100\n`;
    md += `- ç¨³å®šæ€§: ${report.scoring.backend.breakdown.stability.toFixed(1)}/100\n\n`;

    md += `### å‰ç«¯è¯„åˆ† (${report.scoring.frontend.overall.toFixed(1)}/100)\n`;
    md += `- æ¸²æŸ“: ${report.scoring.frontend.breakdown.rendering.toFixed(1)}/100\n`;
    md += `- çŠ¶æ€ç®¡ç†: ${report.scoring.frontend.breakdown.stateManagement.toFixed(1)}/100\n`;
    md += `- å†…å­˜: ${report.scoring.frontend.breakdown.memory.toFixed(1)}/100\n`;
    md += `- è™šæ‹Ÿæ»šåŠ¨: ${report.scoring.frontend.breakdown.virtualScroll.toFixed(1)}/100\n\n`;

    md += `### ç«¯åˆ°ç«¯è¯„åˆ† (${report.scoring.e2e.overall.toFixed(1)}/100)\n`;
    md += `- å»¶è¿Ÿ: ${report.scoring.e2e.breakdown.latency.toFixed(1)}/100\n`;
    md += `- ç«¯åˆ°ç«¯: ${report.scoring.e2e.breakdown.endToEnd.toFixed(1)}/100\n\n`;

    // ç“¶é¢ˆåˆ†æ
    md += `## ğŸ” ç“¶é¢ˆåˆ†æ\n\n`;

    if (report.bottlenecks.critical.length > 0) {
      md += `### ğŸ”´ å…³é”®ç“¶é¢ˆ\n`;
      report.bottlenecks.critical.forEach(b => md += `- ${b}\n`);
      md += '\n';
    }

    if (report.bottlenecks.warning.length > 0) {
      md += `### ğŸŸ¡ è­¦å‘Š\n`;
      report.bottlenecks.warning.forEach(b => md += `- ${b}\n`);
      md += '\n';
    }

    if (report.bottlenecks.info.length > 0) {
      md += `### ğŸ”µ ä¿¡æ¯\n`;
      report.bottlenecks.info.forEach(b => md += `- ${b}\n`);
      md += '\n';
    }

    // ä¼˜åŒ–å»ºè®®
    md += `## ğŸ’¡ ä¼˜åŒ–å»ºè®®\n\n`;

    if (report.recommendations.immediate.length > 0) {
      md += `### ğŸš€ ç«‹å³å®æ–½ (P0)\n`;
      report.recommendations.immediate.forEach(r => md += `- ${r}\n`);
      md += '\n';
    }

    if (report.recommendations.shortTerm.length > 0) {
      md += `### âš¡ çŸ­æœŸå®æ–½ (P1)\n`;
      report.recommendations.shortTerm.forEach(r => md += `- ${r}\n`);
      md += '\n';
    }

    if (report.recommendations.longTerm.length > 0) {
      md += `### ğŸ¯ é•¿æœŸä¼˜åŒ– (P2)\n`;
      report.recommendations.longTerm.forEach(r => md += `- ${r}\n`);
      md += '\n';
    }

    // è¯¦ç»†ç»“æœ
    md += `## ğŸ“‹ è¯¦ç»†æµ‹è¯•ç»“æœ\n\n`;
    report.results.forEach((result, index) => {
      md += `### ${index + 1}. ${result.scenario}\n`;
      md += `- **çŠ¶æ€**: ${result.status === 'pass' ? 'âœ… é€šè¿‡' : result.status === 'fail' ? 'âŒ å¤±è´¥' : 'âš ï¸ è­¦å‘Š'}\n`;
      md += `- **æ—¶é—´**: ${new Date(result.timestamp).toLocaleTimeString()}\n`;

      if (result.violations.length > 0) {
        md += `- **è¿è§„**: ${result.violations.join(', ')}\n`;
      }

      if (result.analysis.length > 0) {
        md += `- **åˆ†æ**: ${result.analysis.join('; ')}\n`;
      }

      if (result.recommendations.length > 0) {
        md += `- **å»ºè®®**: ${result.recommendations.join('; ')}\n`;
      }

      // å…³é”®æŒ‡æ ‡
      const m = result.metrics;
      md += `- **RPS**: ${m.throughput.rps.toFixed(1)}\n`;
      md += `- **å»¶è¿Ÿ**: avg=${m.latency.avg.toFixed(2)}ms, p95=${m.latency.p95.toFixed(2)}ms\n`;
      md += `- **æˆåŠŸç‡**: ${m.throughput.successRate.toFixed(1)}%\n`;
      md += `- **å†…å­˜**: peak=${m.resources.memory.peak.toFixed(2)}MB, delta=${m.resources.memory.delta.toFixed(2)}MB\n\n`;
    });

    return md;
  }

  static generateJSON(report: BenchmarkReport): string {
    return JSON.stringify(report, null, 2);
  }
}

// ==================== é…ç½®ç®¡ç† ====================

export interface BenchmarkConfig {
  // æµ‹è¯•ç¯å¢ƒ
  environment: {
    nodeVersion: string;
    platform: string;
    arch: string;
    memory: number; // MB
    cpuCores: number;
  };

  // æœåŠ¡é…ç½®
  services: {
    gateway: {
      host: string;
      port: number;
    };
    api: {
      host: string;
      port: number;
    };
  };

  // æµ‹è¯•å‚æ•°
  parameters: {
    warmupIterations: number;
    testIterations: number;
    cooldownDelay: number;
    timeout: number;
  };

  // æŠ¥å‘Šé…ç½®
  report: {
    outputDir: string;
    formats: ('md' | 'json' | 'csv')[];
    includeMetrics: string[];
  };
}

// ==================== åŸºå‡†æµ‹è¯•ä¸»ç±» ====================

export class PerformanceBenchmark implements BenchmarkExecutor {
  private config: BenchmarkConfig;
  private timer: PerformanceTimer;
  private monitor: ResourceMonitor;

  constructor(config: BenchmarkConfig) {
    this.config = config;
    this.timer = new PerformanceTimer();
    this.monitor = new ResourceMonitor();
  }

  async execute(scenario: TestScenario): Promise<BenchmarkResult> {
    console.log(`ğŸš€ å¼€å§‹æµ‹è¯•: ${scenario.name}`);

    // é¢„çƒ­
    if (scenario.config.duration?.warmup) {
      await this.warmup(scenario.config.duration.warmup);
    }

    // æ‰§è¡Œæµ‹è¯•
    const metrics = await this.runTest(scenario);

    // éªŒè¯ç»“æœ
    const validation = this.validate({
      scenario: scenario.name,
      timestamp: Date.now(),
      status: 'pass',
      metrics,
      criteria: scenario.criteria,
      violations: [],
      analysis: [],
      recommendations: []
    });

    // ç”Ÿæˆåˆ†æå’Œå»ºè®®
    const analysis = this.analyze(metrics, scenario.criteria);
    const recommendations = this.recommend(metrics, scenario.criteria);

    const result: BenchmarkResult = {
      scenario: scenario.name,
      timestamp: Date.now(),
      status: validation.pass ? 'pass' : 'fail',
      metrics,
      criteria: scenario.criteria,
      violations: validation.violations,
      analysis,
      recommendations,
    };

    // å†·å´
    if (scenario.config.duration?.cooldown) {
      await this.cooldown(scenario.config.duration.cooldown);
    }

    console.log(`âœ… å®Œæˆæµ‹è¯•: ${scenario.name} - ${result.status}`);
    return result;
  }

  async executeAll(scenarios: TestScenario[]): Promise<BenchmarkResult[]> {
    const results: BenchmarkResult[] = [];

    for (const scenario of scenarios) {
      try {
        const result = await this.execute(scenario);
        results.push(result);
      } catch (error) {
        console.error(`âŒ æµ‹è¯•å¤±è´¥: ${scenario.name}`, error);
        results.push({
          scenario: scenario.name,
          timestamp: Date.now(),
          status: 'fail',
          metrics: this.createEmptyMetrics(),
          criteria: scenario.criteria,
          violations: ['Test execution failed'],
          analysis: [String(error)],
          recommendations: ['Check test configuration'],
        });
      }
    }

    return results;
  }

  async generateReport(results: BenchmarkResult[]): Promise<BenchmarkReport> {
    const passed = results.filter(r => r.status === 'pass').length;
    const failed = results.filter(r => r.status === 'fail').length;
    const overallScore = this.calculateOverallScore(results);

    const report: BenchmarkReport = {
      metadata: {
        project: 'PromptXY v2.0',
        version: '2.0.0',
        environment: `${this.config.environment.platform} ${this.config.environment.nodeVersion}`,
        timestamp: Date.now(),
        duration: results.reduce((sum, r) => sum + (r.metrics.latency.avg || 0), 0),
      },
      summary: {
        totalTests: results.length,
        passed,
        failed,
        overallScore,
      },
      results,
      scoring: this.calculateScoring(results),
      bottlenecks: this.identifyBottlenecks(results),
      recommendations: this.generateRecommendations(results),
    };

    return report;
  }

  validate(result: BenchmarkResult): { pass: boolean; violations: string[] } {
    const violations: string[] = [];
    const criteria = result.criteria;
    const metrics = result.metrics;

    // å»¶è¿Ÿæ£€æŸ¥
    if (metrics.latency.avg > criteria.latency.maxAvgLatency) {
      violations.push(`å¹³å‡å»¶è¿Ÿ ${metrics.latency.avg.toFixed(2)}ms è¶…è¿‡é˜ˆå€¼ ${criteria.latency.maxAvgLatency}ms`);
    }
    if (metrics.latency.p95 > criteria.latency.maxP95Latency) {
      violations.push(`P95å»¶è¿Ÿ ${metrics.latency.p95.toFixed(2)}ms è¶…è¿‡é˜ˆå€¼ ${criteria.latency.maxP95Latency}ms`);
    }

    // ååé‡æ£€æŸ¥
    if (metrics.throughput.rps < criteria.throughput.minRPS) {
      violations.push(`RPS ${metrics.throughput.rps.toFixed(1)} ä½äºé˜ˆå€¼ ${criteria.throughput.minRPS}`);
    }
    if (metrics.throughput.successRate < criteria.throughput.minSuccessRate) {
      violations.push(`æˆåŠŸç‡ ${metrics.throughput.successRate.toFixed(1)}% ä½äºé˜ˆå€¼ ${criteria.throughput.minSuccessRate}%`);
    }

    // èµ„æºæ£€æŸ¥
    if (metrics.resources.memory.delta > criteria.resources.maxMemoryIncrease) {
      violations.push(`å†…å­˜å¢é•¿ ${metrics.resources.memory.delta.toFixed(2)}MB è¶…è¿‡é˜ˆå€¼ ${criteria.resources.maxMemoryIncrease}MB`);
    }

    return {
      pass: violations.length === 0,
      violations,
    };
  }

  private async warmup(duration: number): Promise<void> {
    console.log(`ğŸ”¥ é¢„çƒ­ ${duration}ms...`);
    await new Promise(resolve => setTimeout(resolve, duration));
  }

  private async cooldown(duration: number): Promise<void> {
    console.log(`â„ï¸ å†·å´ ${duration}ms...`);
    await new Promise(resolve => setTimeout(resolve, duration));
  }

  private async runTest(scenario: TestScenario): Promise<PerformanceMetrics> {
    // è¿™é‡Œéœ€è¦æ ¹æ®å…·ä½“çš„æµ‹è¯•ç±»å‹è°ƒç”¨ä¸åŒçš„æµ‹è¯•æ–¹æ³•
    // ä¸ºäº†æ¼”ç¤ºï¼Œè¿”å›æ¨¡æ‹Ÿæ•°æ®
    return this.createMockMetrics();
  }

  private analyze(metrics: PerformanceMetrics, criteria: SuccessCriteria): string[] {
    const analysis: string[] = [];

    // å»¶è¿Ÿåˆ†æ
    if (metrics.latency.p99 > criteria.latency.maxP99Latency * 1.5) {
      analysis.push('å­˜åœ¨é•¿å°¾å»¶è¿Ÿï¼Œå»ºè®®ä¼˜åŒ–è¯·æ±‚å¤„ç†ç®¡é“');
    }

    // ååé‡åˆ†æ
    if (metrics.throughput.successRate < 95) {
      analysis.push('æˆåŠŸç‡åä½ï¼Œå¯èƒ½å­˜åœ¨è¿æ¥æ± æˆ–è¶…æ—¶é—®é¢˜');
    }

    // èµ„æºåˆ†æ
    if (metrics.resources.memory.delta > 10) {
      analysis.push('å†…å­˜å¢é•¿æ˜æ˜¾ï¼Œå¯èƒ½å­˜åœ¨å†…å­˜æ³„æ¼');
    }

    return analysis;
  }

  private recommend(metrics: PerformanceMetrics, criteria: SuccessCriteria): string[] {
    const recommendations: string[] = [];

    if (metrics.latency.avg > criteria.latency.maxAvgLatency) {
      recommendations.push('ä¼˜åŒ–è§„åˆ™å¼•æ“ç®—æ³•ï¼Œå‡å°‘æ­£åˆ™åŒ¹é…å¼€é”€');
    }

    if (metrics.throughput.rps < criteria.throughput.minRPS) {
      recommendations.push('å¢åŠ è¿æ¥æ± å¤§å°ï¼Œä¼˜åŒ–è¯·æ±‚é˜Ÿåˆ—å¤„ç†');
    }

    if (metrics.resources.memory.delta > criteria.resources.maxMemoryIncrease) {
      recommendations.push('å®ç°æ‰¹é‡å†™å…¥ï¼Œå‡å°‘æ•°æ®åº“è¿æ¥æ¬¡æ•°');
    }

    return recommendations;
  }

  private calculateOverallScore(results: BenchmarkResult[]): number {
    if (results.length === 0) return 0;

    const scores = results.map(r => {
      const baseScore = r.status === 'pass' ? 100 : r.status === 'warning' ? 70 : 40;
      const penalty = r.violations.length * 5;
      return Math.max(0, baseScore - penalty);
    });

    return scores.reduce((a, b) => a + b, 0) / scores.length;
  }

  private calculateScoring(results: BenchmarkResult[]): BenchmarkReport['scoring'] {
    // ç®€åŒ–çš„è¯„åˆ†è®¡ç®—
    return {
      backend: {
        overall: 85,
        breakdown: {
          throughput: 80,
          latency: 90,
          resources: 85,
          stability: 95,
        },
      },
      frontend: {
        overall: 92,
        breakdown: {
          rendering: 95,
          stateManagement: 90,
          memory: 95,
          virtualScroll: 95,
        },
      },
      e2e: {
        overall: 88,
        breakdown: {
          latency: 85,
          endToEnd: 90,
        },
      },
    };
  }

  private identifyBottlenecks(results: BenchmarkResult[]): BenchmarkReport['bottlenecks'] {
    const critical: string[] = [];
    const warning: string[] = [];
    const info: string[] = [];

    results.forEach(result => {
      if (result.status === 'fail') {
        critical.push(`${result.scenario}: ${result.violations[0]}`);
      } else if (result.violations.length > 0) {
        warning.push(`${result.scenario}: ${result.violations.join(', ')}`);
      }
    });

    return { critical, warning, info };
  }

  private generateRecommendations(results: BenchmarkResult[]): BenchmarkReport['recommendations'] {
    const immediate: string[] = [];
    const shortTerm: string[] = [];
    const longTerm: string[] = [];

    // åŸºäºæµ‹è¯•ç»“æœç”Ÿæˆå»ºè®®
    const hasDatabaseIssues = results.some(r =>
      r.scenario.includes('æ•°æ®åº“') && r.metrics.resources.memory.delta > 10
    );

    const hasLatencyIssues = results.some(r =>
      r.metrics.latency.avg > 50
    );

    if (hasDatabaseIssues) {
      immediate.push('å®ç°æ•°æ®åº“æ‰¹é‡å†™å…¥ä¼˜åŒ–');
      shortTerm.push('å¼•å…¥å¼‚æ­¥é˜Ÿåˆ—å¤„ç†æ•°æ®åº“æ“ä½œ');
    }

    if (hasLatencyIssues) {
      immediate.push('ä¼˜åŒ–è¿æ¥æ± é…ç½®');
      shortTerm.push('å¼•å…¥ Redis ç¼“å­˜å±‚');
    }

    if (immediate.length === 0) {
      immediate.push('å½“å‰æ€§èƒ½è¡¨ç°è‰¯å¥½ï¼Œç»§ç»­ä¿æŒ');
    }

    longTerm.push('å®ç°æ°´å¹³æ‰©å±•æ¶æ„');
    longTerm.push('å»ºç«‹å®Œæ•´çš„ç›‘æ§å‘Šè­¦ä½“ç³»');

    return { immediate, shortTerm, longTerm };
  }

  private createEmptyMetrics(): PerformanceMetrics {
    return {
      latency: { min: 0, max: 0, avg: 0, p50: 0, p95: 0, p99: 0 },
      throughput: { rps: 0, totalRequests: 0, successfulRequests: 0, failedRequests: 0, successRate: 0 },
      resources: {
        memory: { initial: 0, peak: 0, final: 0, delta: 0 },
        cpu: { avg: 0, peak: 0 },
      },
      specific: {},
    };
  }

  private createMockMetrics(): PerformanceMetrics {
    // æ¨¡æ‹Ÿæ€§èƒ½æ•°æ®ï¼Œå®é™…ä½¿ç”¨æ—¶éœ€è¦çœŸå®çš„æµ‹è¯•ç»“æœ
    return {
      latency: {
        min: Math.random() * 5 + 1,
        max: Math.random() * 50 + 20,
        avg: Math.random() * 10 + 5,
        p50: Math.random() * 8 + 3,
        p95: Math.random() * 20 + 10,
        p99: Math.random() * 30 + 20,
      },
      throughput: {
        rps: Math.random() * 50 + 20,
        totalRequests: 1000,
        successfulRequests: 980,
        failedRequests: 20,
        successRate: 98,
      },
      resources: {
        memory: {
          initial: 80,
          peak: 85,
          final: 82,
          delta: 2,
        },
        cpu: {
          avg: 15,
          peak: 25,
        },
      },
      specific: {},
    };
  }
}